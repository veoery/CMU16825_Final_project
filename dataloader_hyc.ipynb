{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImqX2eh9JkjZ",
        "outputId": "2c50aff3-a12f-4bf0-f4a9-c9b83e0c77c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT = \"/content/drive/MyDrive/Omni-CAD-subset-complete\""
      ],
      "metadata": {
        "id": "PBD4H3POO2LV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/veoery/CMU16825_Final_project.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZwkjCWgSry0",
        "outputId": "a37f959d-392d-4b9b-930f-0976ba217c05"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CMU16825_Final_project' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/CMU16825_Final_project\n",
        "!git pull"
      ],
      "metadata": {
        "id": "9uARcslaVOvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7990c3a5",
        "outputId": "f7002938-ea84-46d9-a9ef-d5a0a1dc9f5f"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "# Add the project root to sys.path to import local modules\n",
        "sys.path.append(\"/content/CMU16825_Final_project\")\n",
        "\n",
        "# Test 1: Check directory structure\n",
        "def test_directory_structure():\n",
        "    \"\"\"Verify your data directories exist.\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"TEST 1: Checking directory structure\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    required_dirs = {\n",
        "        \"truncated_json\": f\"{ROOT}/json_truncated\",\n",
        "        \"full_json\": f\"{ROOT}/json\",\n",
        "        \"images\": f\"{ROOT}/img\",\n",
        "        \"point_clouds\": f\"{ROOT}/pointcloud\",\n",
        "    }\n",
        "\n",
        "    for name, path in required_dirs.items():\n",
        "        if os.path.isdir(path):\n",
        "            num_files = len(os.listdir(path))\n",
        "            print(f\"✓ {name}: {path} ({num_files} folders)\")\n",
        "        else:\n",
        "            print(f\"✗ {name}: {path} (NOT FOUND)\")\n",
        "\n",
        "    return required_dirs\n",
        "\n",
        "\n",
        "# Test 2: List sample files\n",
        "def test_list_files(required_dirs):\n",
        "    \"\"\"List sample files from each directory.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"TEST 2: Listing sample files\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for name, path in required_dirs.items():\n",
        "        print(f\"\\n{name} (top-level entries):\")\n",
        "        top_level_entries = sorted(os.listdir(path))\n",
        "        for entry in top_level_entries[:3]:\n",
        "            print(f\"  - {entry} {'(dir)' if os.path.isdir(os.path.join(path, entry)) else '(file)'}\")\n",
        "\n",
        "        # Now, if it's a JSON directory, pick one of the top-level directories and list some actual json files inside it\n",
        "        if name == \"truncated_json\" or name == \"full_json\":\n",
        "            if top_level_entries:\n",
        "                sample_sub_dir_name = top_level_entries[0]\n",
        "                sample_sub_dir_path = os.path.join(path, sample_sub_dir_name)\n",
        "                if os.path.isdir(sample_sub_dir_path):\n",
        "                    print(f\"  - (First 3 .json files in {sample_sub_dir_name}):\")\n",
        "                    json_files_in_subdir = []\n",
        "                    # Use iglob to be efficient, only take the first 3\n",
        "                    for json_file in glob.iglob(os.path.join(sample_sub_dir_path, '**', '*.json'), recursive=True):\n",
        "                        json_files_in_subdir.append(json_file)\n",
        "                        if len(json_files_in_subdir) >= 3:\n",
        "                            break\n",
        "                    for f in sorted(json_files_in_subdir):\n",
        "                        print(f\"    - {Path(f).name}\")\n",
        "                else:\n",
        "                    print(f\"    (No subdirectories to list JSON files in {sample_sub_dir_name})\")\n",
        "        elif top_level_entries: # For images/pointclouds, list first 3 files if they are directly in the root\n",
        "            actual_files = sorted([f for f in glob.iglob(os.path.join(path, '*')) if os.path.isfile(f)])\n",
        "            if actual_files:\n",
        "                print(f\"  - (First 3 files in {name}):\")\n",
        "                for f in actual_files[:3]:\n",
        "                    print(f\"    - {Path(f).name}\")\n",
        "\n",
        "\n",
        "# Test 3: Load sample data\n",
        "def test_load_sample_data(required_dirs):\n",
        "    \"\"\"Try loading sample JSON files.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"TEST 3: Loading sample JSON data\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    sample_file = None\n",
        "    truncated_dir = required_dirs[\"truncated_json\"]\n",
        "    top_level_entries = sorted(os.listdir(truncated_dir))\n",
        "\n",
        "    if top_level_entries:\n",
        "        sample_sub_dir_name = top_level_entries[0]\n",
        "        sample_sub_dir_path = os.path.join(truncated_dir, sample_sub_dir_name)\n",
        "        if os.path.isdir(sample_sub_dir_path):\n",
        "            # Find the first JSON file in the sample subdirectory\n",
        "            json_files_in_subdir = glob.glob(os.path.join(sample_sub_dir_path, '**', '*.json'), recursive=True)\n",
        "            if json_files_in_subdir:\n",
        "                sample_file = sorted(json_files_in_subdir)[0]\n",
        "\n",
        "    if sample_file:\n",
        "        try:\n",
        "            with open(sample_file, 'r') as f:\n",
        "                data = json.load(f)\n",
        "            print(f\"✓ Successfully loaded: {Path(sample_file).name}\")\n",
        "            print(f\"  Data type: {type(data)}\")\n",
        "            if isinstance(data, dict):\n",
        "                print(f\"  Keys: {list(data.keys())[:5]}\")\n",
        "            elif isinstance(data, list):\n",
        "                print(f\"  Length: {len(data)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Error loading {sample_file}: {e}\")\n",
        "    else:\n",
        "        print(\"No sample JSON file found to load for testing.\")\n",
        "\n",
        "\n",
        "# Test 4: Create path lists\n",
        "def test_create_path_lists(required_dirs):\n",
        "    \"\"\"Create path lists like in your training script.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"TEST 4: Creating path lists\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    truncated_dir = required_dirs[\"truncated_json\"]\n",
        "    full_dir = required_dirs[\"full_json\"]\n",
        "\n",
        "    # truncated_paths = []\n",
        "    # full_paths = []\n",
        "\n",
        "    truncated_paths = sorted(glob.glob(truncated_dir + \"/**/*.json\", recursive=True))\n",
        "    full_paths = []\n",
        "    for tr in truncated_paths:\n",
        "        base = os.path.basename(tr).split(\"_tr_\")[0] + \".json\"\n",
        "        # Reconstruct the full path preserving the subdirectory structure\n",
        "        rel_dir = os.path.dirname(tr).replace(truncated_dir,\"\").lstrip(\"/\")\n",
        "        full_path = os.path.join(full_dir, rel_dir, base) if rel_dir else os.path.join(full_dir, base)\n",
        "        full_paths.append(full_path)\n",
        "\n",
        "\n",
        "    # top_level_entries = sorted(os.listdir(truncated_dir))\n",
        "    # if top_level_entries:\n",
        "    #     sample_sub_dir_name = top_level_entries[0]\n",
        "    #     sample_sub_dir_path = os.path.join(truncated_dir, sample_sub_dir_name)\n",
        "    #     if os.path.isdir(sample_sub_dir_path):\n",
        "    #         # Find a few JSON files in the sample subdirectory\n",
        "    #         sample_json_files = sorted(glob.glob(os.path.join(sample_sub_dir_path, '**', '*.json'), recursive=True))[:3]\n",
        "    #         for tr_path in sample_json_files:\n",
        "    #             relative_path = os.path.relpath(tr_path, truncated_dir)\n",
        "    #             full_path = os.path.join(full_dir, relative_path)\n",
        "    #             exists = os.path.exists(full_path)\n",
        "    #             status = \"✓\" if exists else \"✗\"\n",
        "    #             print(f\"{status} {Path(tr_path).name} -> {Path(full_path).name}\")\n",
        "    #             truncated_paths.append(tr_path)\n",
        "    #             full_paths.append(full_path)\n",
        "\n",
        "    if not truncated_paths:\n",
        "        print(\"No truncated JSON files found in sample subdirectory to create path lists.\")\n",
        "    else:\n",
        "        print(f\"Created path lists for {len(truncated_paths)} sample files.\")\n",
        "\n",
        "    return truncated_paths, full_paths\n",
        "\n",
        "\n",
        "# Test 5: Test dataloader import (only in Colab with dependencies)\n",
        "def test_dataloader_import():\n",
        "    \"\"\"Test if dataloader can be imported.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"TEST 5: Testing dataloader import\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    try:\n",
        "        from cad_mllm.data import get_autocomplete_dataloader\n",
        "        print(\"✓ Successfully imported get_autocomplete_dataloader\")\n",
        "        return True\n",
        "    except ImportError as e:\n",
        "        print(f\"⚠ Could not import (expected if dependencies not installed): {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "# Test 6: Test encoders (only if models are loaded)\n",
        "def test_encoders():\n",
        "    \"\"\"Test if encoders can be imported.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"TEST 6: Testing encoder imports\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    try:\n",
        "        from cad_mllm.encoders import ImageEncoder, MichelangeloPointEncoder\n",
        "        print(\"✓ Successfully imported ImageEncoder\")\n",
        "        print(\"✓ Successfully imported MichelangeloPointEncoder\")\n",
        "        return True\n",
        "    except ImportError as e:\n",
        "        print(f\"⚠ Could not import encoders: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Run all tests.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"CAD-MLLM DATALOADER TEST SCRIPT\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Test directory structure\n",
        "    required_dirs = test_directory_structure()\n",
        "\n",
        "    # Test file listing\n",
        "    test_list_files(required_dirs)\n",
        "\n",
        "    # Test loading data\n",
        "    test_load_sample_data(required_dirs)\n",
        "\n",
        "    # Test path creation\n",
        "    truncated_paths, full_paths = test_create_path_lists(required_dirs)\n",
        "\n",
        "    # Test imports\n",
        "    dataloader_ok = test_dataloader_import()\n",
        "    encoders_ok = test_encoders()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"TEST SUMMARY\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    if dataloader_ok and encoders_ok:\n",
        "        print(\"✓ All imports successful!\")\n",
        "        print(\"\\nYou can now use the dataloader like this:\")\n",
        "        print(\"\"\"\n",
        "from cad_mllm.data import get_autocomplete_dataloader\n",
        "from cad_mllm.encoders import ImageEncoder, MichelangeloPointEncoder\n",
        "\n",
        "# Initialize encoders (optional, can pass None)\n",
        "image_encoder = ImageEncoder(freeze=True)\n",
        "\n",
        "# Create dataloader\n",
        "train_loader = get_autocomplete_dataloader(\n",
        "    truncated_paths,\n",
        "    full_paths,\n",
        "    image_dir=\"/path/to/images\",\n",
        "    pc_dir=\"/path/to/point_clouds\",\n",
        "    tokenizer=tokenizer,\n",
        "    image_encoder=image_encoder,\n",
        "    batch_size=4\n",
        ")\n",
        "\n",
        "# Training loop\n",
        "for batch in train_loader:\n",
        "    batch = {k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()}\n",
        "    outputs = model(**batch)\n",
        "    loss = outputs.loss\n",
        "    loss.backward()\n",
        "        \"\"\")\n",
        "    else:\n",
        "        print(\"⚠ Some imports failed, but the code structure should be correct\")\n",
        "        print(\"  This may be due to missing dependencies\")\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CAD-MLLM DATALOADER TEST SCRIPT\n",
            "============================================================\n",
            "============================================================\n",
            "TEST 1: Checking directory structure\n",
            "============================================================\n",
            "✓ truncated_json: /content/drive/MyDrive/Omni-CAD-subset-complete/json_truncated (100 folders)\n",
            "✓ full_json: /content/drive/MyDrive/Omni-CAD-subset-complete/json (100 folders)\n",
            "✓ images: /content/drive/MyDrive/Omni-CAD-subset-complete/img (100 folders)\n",
            "✓ point_clouds: /content/drive/MyDrive/Omni-CAD-subset-complete/pointcloud (100 folders)\n",
            "\n",
            "============================================================\n",
            "TEST 2: Listing sample files\n",
            "============================================================\n",
            "\n",
            "truncated_json (top-level entries):\n",
            "  - 0000 (dir)\n",
            "  - 0001 (dir)\n",
            "  - 0002 (dir)\n",
            "  - (First 3 .json files in 0000):\n",
            "    - 00000347_00005_tr_03.json\n",
            "    - 00000669_00019_tr_03.json\n",
            "    - 00002009_00012_tr_01.json\n",
            "\n",
            "full_json (top-level entries):\n",
            "  - 0000 (dir)\n",
            "  - 0001 (dir)\n",
            "  - 0002 (dir)\n",
            "  - (First 3 .json files in 0000):\n",
            "    - 00007265_00005.json\n",
            "    - 00007282_00001.json\n",
            "    - 00009435_00002.json\n",
            "\n",
            "images (top-level entries):\n",
            "  - 0000 (dir)\n",
            "  - 0001 (dir)\n",
            "  - 0002 (dir)\n",
            "\n",
            "point_clouds (top-level entries):\n",
            "  - 0000 (dir)\n",
            "  - 0001 (dir)\n",
            "  - 0002 (dir)\n",
            "\n",
            "============================================================\n",
            "TEST 3: Loading sample JSON data\n",
            "============================================================\n",
            "✓ Successfully loaded: 00000071_00005_tr_01.json\n",
            "  Data type: <class 'dict'>\n",
            "  Keys: ['entities', 'properties', 'sequence', 'truncation_metadata']\n",
            "\n",
            "============================================================\n",
            "TEST 4: Creating path lists\n",
            "============================================================\n",
            "Created path lists for 138737 sample files.\n",
            "\n",
            "============================================================\n",
            "TEST 5: Testing dataloader import\n",
            "============================================================\n",
            "⚠ Could not import (expected if dependencies not installed): No module named 'michelangelo'\n",
            "\n",
            "============================================================\n",
            "TEST 6: Testing encoder imports\n",
            "============================================================\n",
            "⚠ Could not import encoders: No module named 'michelangelo'\n",
            "\n",
            "============================================================\n",
            "TEST SUMMARY\n",
            "============================================================\n",
            "⚠ Some imports failed, but the code structure should be correct\n",
            "  This may be due to missing dependencies\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gkYsYUFxVfa9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}