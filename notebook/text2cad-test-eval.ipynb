{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "scrolled": true
      },
      "source": [
        "%uv pip install --upgrade pip\n",
        "%uv pip install gdown\n",
        "%uv pip install torch\n",
        "%uv pip install transformers\n",
        "%uv pip install peft\n",
        "%uv pip install safetensors\n",
        "%uv pip install gdown\n",
        "%uv pip install modal"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.12.6 environment at: /usr/local\u001b[0m\r\n",
            "\u001b[37m\u280b\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u280b\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mpip==25.3                                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2m                                                                              \u001b[0m\r\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 27ms\u001b[0m\u001b[0m\r\n",
            "\u001b[37m\u280b\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/0)                                                   \r\u001b[2K\u001b[37m\u280b\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpip       \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.70 MiB                      \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpip       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/1.70 MiB                    \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpip       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 32.00 KiB/1.70 MiB                    \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpip       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 48.00 KiB/1.70 MiB                    \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpip       \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 62.13 KiB/1.70 MiB                    \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpip       \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 78.13 KiB/1.70 MiB                    \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpip       \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 94.13 KiB/1.70 MiB                    \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpip       \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 110.13 KiB/1.70 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpip       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 126.13 KiB/1.70 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpip       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 142.13 KiB/1.70 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpip       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 158.13 KiB/1.70 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpip       \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 174.13 KiB/1.70 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpip       \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 190.13 KiB/1.70 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpip       \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 206.13 KiB/1.70 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpip       \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 222.13 KiB/1.70 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpip       \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 238.13 KiB/1.70 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpip       \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 254.13 KiB/1.70 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpip       \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 382.13 KiB/1.70 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpip       \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 1.48 MiB/1.70 MiB                     \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \r\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 120ms\u001b[0m\u001b[0m\r\n",
            "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 75ms\u001b[0m\u001b[0m\r\n",
            "\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/0] \u001b[2mInstalling wheels...                                 \u001b[0m\r\u001b[2K\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/1] \u001b[2mInstalling wheels...                                 \u001b[0m\r\u001b[2K\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/1] \u001b[2mpip==25.3                                            \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 [1/1] \u001b[2mpip==25.3                                            \u001b[0m\r\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 113ms\u001b[0m\u001b[0m\r\n",
            " \u001b[31m-\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==24.3.1\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==25.3\u001b[0m\r\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "\u001b[2mUsing Python 3.12.6 environment at: /usr/local\u001b[0m\r\n",
            "\u001b[37m\u280b\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u280b\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mgdown==5.2.0                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mbeautifulsoup4==4.13.5                                                        \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mfilelock==3.13.1                                                              \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mrequests==2.32.5                                                              \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mrequests==2.32.5                                                              \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mtqdm==4.67.1                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2msoupsieve==2.8                                                                \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mtyping-extensions==4.12.2                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mpysocks==1.7.1                                                                \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mcharset-normalizer==3.4.3                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2midna==3.10                                                                    \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2murllib3==2.5.0                                                                \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mcertifi==2024.8.30                                                            \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2m                                                                              \u001b[0m\r\u001b[2K\u001b[2mResolved \u001b[1m12 packages\u001b[0m \u001b[2min 64ms\u001b[0m\u001b[0m\r\n",
            "\u001b[37m\u280b\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/0)                                                   \r\u001b[2K\u001b[37m\u280b\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)                                                   \r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)                                                   \r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)\r\n",
            "\u001b[2mpysocks   \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/16.33 KiB                     \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)\r\n",
            "\u001b[2mpysocks   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 16.00 KiB/16.33 KiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)\r\n",
            "\u001b[2mpysocks   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 16.00 KiB/16.33 KiB\r\n",
            "\u001b[2mgdown     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/17.81 KiB                     \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)\r\n",
            "\u001b[2mpysocks   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 16.00 KiB/16.33 KiB\r\n",
            "\u001b[2mgdown     \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 14.89 KiB/17.81 KiB                   \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)\r\n",
            "\u001b[2mpysocks   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 16.33 KiB/16.33 KiB\r\n",
            "\u001b[2mgdown     \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 14.89 KiB/17.81 KiB                   \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)\r\n",
            "\u001b[2mgdown     \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 14.89 KiB/17.81 KiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)\r\n",
            "\u001b[2mgdown     \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 17.81 KiB/17.81 KiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)                                                   \r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2m\u001b[0m (2/2)                                                                        \r\u001b[2K\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 11ms\u001b[0m\u001b[0m\r\n",
            "\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/0] \u001b[2mInstalling wheels...                                 \u001b[0m\r\u001b[2K\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/2] \u001b[2mInstalling wheels...                                 \u001b[0m\r\u001b[2K\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/2] \u001b[2mpysocks==1.7.1                                       \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [1/2] \u001b[2mpysocks==1.7.1                                       \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [1/2] \u001b[2mgdown==5.2.0                                         \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 [2/2] \u001b[2mgdown==5.2.0                                         \u001b[0m\r\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 85ms\u001b[0m\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mgdown\u001b[0m\u001b[2m==5.2.0\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mpysocks\u001b[0m\u001b[2m==1.7.1\u001b[0m\r\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "\u001b[2mUsing Python 3.12.6 environment at: /usr/local\u001b[0m\r\n",
            "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 9ms\u001b[0m\u001b[0m\r\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "\u001b[2mUsing Python 3.12.6 environment at: /usr/local\u001b[0m\r\n",
            "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 8ms\u001b[0m\u001b[0m\r\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "\u001b[2mUsing Python 3.12.6 environment at: /usr/local\u001b[0m\r\n",
            "\u001b[37m\u280b\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u280b\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mpeft==0.18.0                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnumpy==2.1.2                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mpackaging==25.0                                                               \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mpsutil==7.0.0                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mpyyaml==6.0.2                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mtorch==2.8.0+cu129                                                            \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mtransformers==4.56.0                                                          \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mtqdm==4.67.1                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2maccelerate==1.10.1                                                            \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2msafetensors==0.6.2                                                            \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mhuggingface-hub==0.34.4                                                       \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mfilelock==3.13.1                                                              \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mtyping-extensions==4.12.2                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2msetuptools==70.2.0                                                            \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2msetuptools==70.2.0                                                            \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2msympy==1.13.3                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnetworkx==3.3                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mjinja2==3.1.4                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mfsspec==2024.6.1                                                              \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnvidia-cuda-nvrtc-cu12==12.9.86                                               \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnvidia-cuda-nvrtc-cu12==12.9.86                                               \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2m                                                                              \u001b[0m\r\u001b[2K\u001b[2mResolved \u001b[1m43 packages\u001b[0m \u001b[2min 203ms\u001b[0m\u001b[0m\r\n",
            "\u001b[37m\u280b\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/0)                                                   \r\u001b[2K\u001b[37m\u280b\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpeft      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/543.39 KiB                    \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpeft      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.92 KiB/543.39 KiB                  \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpeft      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 30.92 KiB/543.39 KiB                  \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpeft      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 46.92 KiB/543.39 KiB                  \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpeft      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 62.92 KiB/543.39 KiB                  \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpeft      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 78.92 KiB/543.39 KiB                  \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpeft      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 94.92 KiB/543.39 KiB                  \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpeft      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 110.92 KiB/543.39 KiB                 \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpeft      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 126.92 KiB/543.39 KiB                 \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpeft      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 142.92 KiB/543.39 KiB                 \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpeft      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 158.92 KiB/543.39 KiB                 \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpeft      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 174.92 KiB/543.39 KiB                 \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpeft      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 190.92 KiB/543.39 KiB                 \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpeft      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 206.92 KiB/543.39 KiB                 \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpeft      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 222.92 KiB/543.39 KiB                 \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpeft      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 238.92 KiB/543.39 KiB                 \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mpeft      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 254.92 KiB/543.39 KiB                 \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \r\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 49ms\u001b[0m\u001b[0m\r\n",
            "\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/0] \u001b[2mInstalling wheels...                                 \u001b[0m\r\u001b[2K\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/1] \u001b[2mInstalling wheels...                                 \u001b[0m\r\u001b[2K\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/1] \u001b[2mpeft==0.18.0                                         \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 [1/1] \u001b[2mpeft==0.18.0                                         \u001b[0m\r\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 90ms\u001b[0m\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mpeft\u001b[0m\u001b[2m==0.18.0\u001b[0m\r\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "\u001b[2mUsing Python 3.12.6 environment at: /usr/local\u001b[0m\r\n",
            "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 4ms\u001b[0m\u001b[0m\r\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "\u001b[2mUsing Python 3.12.6 environment at: /usr/local\u001b[0m\r\n",
            "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 6ms\u001b[0m\u001b[0m\r\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "\u001b[2mUsing Python 3.12.6 environment at: /usr/local\u001b[0m\r\n",
            "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 9ms\u001b[0m\u001b[0m\r\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "scrolled": true
      },
      "source": [
        "%cd /mnt/l43d\n",
        "!ls\n",
        "import os\n",
        "weight_file = \"/mnt/l43d/adapter_model.safetensors\"\n",
        "\n",
        "if os.path.exists(weight_file):\n",
        "    print(\"\u2705 Weights found. You are good to go!\")\n",
        "else:\n",
        "    print(\"\u274c Weights MISSING. You only uploaded the Windows metadata shortcut.\")\n",
        "    print(\"Please upload the actual 1GB+ .safetensors file.\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/__modal/volumes/vo-xU2jv4A8E4IUtMxIszxpju\n",
            "CMU16825_Final_project\r\n",
            "README.md\r\n",
            "README.md\uf03aZone.Identifier\r\n",
            "adapter_config.json\r\n",
            "adapter_config.json\uf03aZone.Identifier\r\n",
            "adapter_model.safetensors\r\n",
            "adapter_model.safetensors\uf03aZone.Identifier\r\n",
            "added_tokens.json\r\n",
            "added_tokens.json\uf03aZone.Identifier\r\n",
            "chat_template.jinja\r\n",
            "chat_template.jinja\uf03aZone.Identifier\r\n",
            "config.pt\r\n",
            "config.pt\uf03aZone.Identifier\r\n",
            "generated_cad\r\n",
            "merges.txt\r\n",
            "merges.txt\uf03aZone.Identifier\r\n",
            "special_tokens_map.json\r\n",
            "special_tokens_map.json\uf03aZone.Identifier\r\n",
            "tokenizer.json\r\n",
            "tokenizer.json\uf03aZone.Identifier\r\n",
            "tokenizer_config.json\r\n",
            "tokenizer_config.json\uf03aZone.Identifier\r\n",
            "trainer_state.pt\r\n",
            "trainer_state.pt\uf03aZone.Identifier\r\n",
            "vocab.json\r\n",
            "vocab.json\uf03aZone.Identifier\r\n",
            "\u2705 Weights found. You are good to go!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "model_path = \"/mnt/l43d\"\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "\n",
        "# Clear GPU memory first\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(\"Loading base model...\")\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "  \"Qwen/Qwen3-8B\",\n",
        "  torch_dtype=torch.bfloat16,\n",
        "  device_map=\"cuda:0\",  # Explicitly use GPU\n",
        "  trust_remote_code=True,\n",
        ")\n",
        "\n",
        "print(\"Loading LoRA adapter...\")\n",
        "# Load the LoRA adapter from local checkpoint\n",
        "model = PeftModel.from_pretrained(\n",
        "  base_model,\n",
        "  model_path,\n",
        "  is_trainable=False,\n",
        ")\n",
        "\n",
        "# Load tokenizer\n",
        "print(\"Loading tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-8B\", trust_remote_code=True)\n",
        "if tokenizer.pad_token is None:\n",
        "  tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model.eval()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading base model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7af966cfd8864ee982bfe6ed9517a54d",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "config.json:   0%|          | 0.00/728 [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7357ffd157d8454a95bdbc9dc1238d43",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "541d220b00ab4db5940d64a780ba6514",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1264eea7c974af0a7c5e879532089cf",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "model-00002-of-00005.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1722b556dd6143c78dec7055865f4525",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "model-00003-of-00005.safetensors:   0%|          | 0.00/3.96G [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9727f0a0d3be4ee2959bfd2d4a2d3486",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "model-00005-of-00005.safetensors:   0%|          | 0.00/1.24G [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b1599227ead4d6b8268d8c3e6315fb0",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "model-00004-of-00005.safetensors:   0%|          | 0.00/3.19G [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b0f04aeb42346ac858b39d88d35843f",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "model-00001-of-00005.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19ca9e28130d4b38a357a681fa1df44f",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "759b63a506ba42f19bb60f2787a48bdb",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading LoRA adapter...\n",
            "Loading tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e25c8c3dfa24293995d14c3dadb75e0",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "tokenizer_config.json: 0.00B [00:00, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25c6260532674fdeb9f99313e3bfad6e",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "vocab.json: 0.00B [00:00, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0a2da37df5b4e5ebef1c21d4586c02d",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "merges.txt: 0.00B [00:00, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50d5903c739b46baa0b0dee2de8963b6",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): Qwen3ForCausalLM(\n      (model): Qwen3Model(\n        (embed_tokens): Embedding(151936, 4096)\n        (layers): ModuleList(\n          (0-35): 36 x Qwen3DecoderLayer(\n            (self_attn): Qwen3Attention(\n              (q_proj): lora.Linear(\n                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=64, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear(\n                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=64, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear(\n                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=64, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear(\n                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=64, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n            )\n            (mlp): Qwen3MLP(\n              (gate_proj): lora.Linear(\n                (base_layer): Linear(in_features=4096, out_features=12288, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=64, out_features=12288, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear(\n                (base_layer): Linear(in_features=4096, out_features=12288, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=64, out_features=12288, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear(\n                (base_layer): Linear(in_features=12288, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=12288, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=64, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n            (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n          )\n        )\n        (norm): Qwen3RMSNorm((4096,), eps=1e-06)\n        (rotary_emb): Qwen3RotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=4096, out_features=151936, bias=False)\n    )\n  )\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "scrolled": true
      },
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Step 1: Clone the repo\n",
        "print(\"Cloning repository...\")\n",
        "subprocess.run([\"git\", \"clone\", \"https://github.com/veoery/CMU16825_Final_project.git\"], check=False)\n",
        "os.chdir(\"CMU16825_Final_project\")\n",
        "\n",
        "# Step 2: Install dependencies\n",
        "print(\"Installing dependencies...\")\n",
        "subprocess.run([\"pip\", \"install\", \"-e\", \".\"], check=True)\n",
        "\n",
        "# Step 3: Load and generate with your trained model\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "import json\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning repository...\n",
            "Installing dependencies...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "fatal: destination path 'CMU16825_Final_project' already exists and is not an empty directory.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///__modal/volumes/vo-xU2jv4A8E4IUtMxIszxpju/CMU16825_Final_project\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Checking if build backend supports build_editable: started\n",
            "  Checking if build backend supports build_editable: finished with status 'done'\n",
            "  Getting requirements to build editable: started\n",
            "  Getting requirements to build editable: finished with status 'done'\n",
            "  Installing backend dependencies: started\n",
            "  Installing backend dependencies: finished with status 'done'\n",
            "  Preparing editable metadata (pyproject.toml): started\n",
            "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
            "Requirement already satisfied: accelerate>=0.25.0 in /usr/local/lib/python3.12/site-packages (from cad-mllm==0.1.0) (1.10.1)\n",
            "Collecting cython (from cad-mllm==0.1.0)\n",
            "  Downloading cython-3.2.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting editables>=0.5 (from cad-mllm==0.1.0)\n",
            "  Downloading editables-0.5-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting einops>=0.7.0 (from cad-mllm==0.1.0)\n",
            "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting hatchling>=1.27.0 (from cad-mllm==0.1.0)\n",
            "  Downloading hatchling-1.27.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.12/site-packages (from cad-mllm==0.1.0) (2.1.2)\n",
            "Collecting omegaconf>=2.3.0 (from cad-mllm==0.1.0)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: peft>=0.7.0 in /usr/local/lib/python3.12/site-packages (from cad-mllm==0.1.0) (0.18.0)\n",
            "Collecting pytorch-lightning>=2.5.6 (from cad-mllm==0.1.0)\n",
            "  Downloading pytorch_lightning-2.5.6-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: sentencepiece>=0.1.99 in /usr/local/lib/python3.12/site-packages (from cad-mllm==0.1.0) (0.2.1)\n",
            "Requirement already satisfied: tensorboard>=2.15.0 in /usr/local/lib/python3.12/site-packages (from cad-mllm==0.1.0) (2.20.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/site-packages (from cad-mllm==0.1.0) (2.8.0+cu129)\n",
            "Requirement already satisfied: tqdm>=4.66.0 in /usr/local/lib/python3.12/site-packages (from cad-mllm==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: transformers>=4.36.0 in /usr/local/lib/python3.12/site-packages (from cad-mllm==0.1.0) (4.56.0)\n",
            "Collecting wandb>=0.16.0 (from cad-mllm==0.1.0)\n",
            "  Downloading wandb-0.23.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/site-packages (from accelerate>=0.25.0->cad-mllm==0.1.0) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/site-packages (from accelerate>=0.25.0->cad-mllm==0.1.0) (7.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/site-packages (from accelerate>=0.25.0->cad-mllm==0.1.0) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/site-packages (from accelerate>=0.25.0->cad-mllm==0.1.0) (0.34.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/site-packages (from accelerate>=0.25.0->cad-mllm==0.1.0) (0.6.2)\n",
            "Collecting pathspec>=0.10.1 (from hatchling>=1.27.0->cad-mllm==0.1.0)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pluggy>=1.0.0 (from hatchling>=1.27.0->cad-mllm==0.1.0)\n",
            "  Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting trove-classifiers (from hatchling>=1.27.0->cad-mllm==0.1.0)\n",
            "  Downloading trove_classifiers-2025.11.14.15-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.25.0->cad-mllm==0.1.0) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.25.0->cad-mllm==0.1.0) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.25.0->cad-mllm==0.1.0) (2.32.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.25.0->cad-mllm==0.1.0) (4.12.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.25.0->cad-mllm==0.1.0) (1.1.9)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.3.0->cad-mllm==0.1.0)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting torchmetrics>0.7.0 (from pytorch-lightning>=2.5.6->cad-mllm==0.1.0)\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning>=2.5.6->cad-mllm==0.1.0)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=2.5.6->cad-mllm==0.1.0) (3.10.8)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.5.6->cad-mllm==0.1.0) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.5.6->cad-mllm==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.5.6->cad-mllm==0.1.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.5.6->cad-mllm==0.1.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.5.6->cad-mllm==0.1.0) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.5.6->cad-mllm==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/site-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.5.6->cad-mllm==0.1.0) (3.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning>=2.5.6->cad-mllm==0.1.0) (70.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/site-packages (from tensorboard>=2.15.0->cad-mllm==0.1.0) (2.3.1)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/site-packages (from tensorboard>=2.15.0->cad-mllm==0.1.0) (1.74.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/site-packages (from tensorboard>=2.15.0->cad-mllm==0.1.0) (3.8.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/site-packages (from tensorboard>=2.15.0->cad-mllm==0.1.0) (11.0.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/site-packages (from tensorboard>=2.15.0->cad-mllm==0.1.0) (5.29.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/site-packages (from tensorboard>=2.15.0->cad-mllm==0.1.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/site-packages (from tensorboard>=2.15.0->cad-mllm==0.1.0) (3.1.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->cad-mllm==0.1.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->cad-mllm==0.1.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->cad-mllm==0.1.0) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.9.86 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->cad-mllm==0.1.0) (12.9.86)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.9.79 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->cad-mllm==0.1.0) (12.9.79)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.9.79 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->cad-mllm==0.1.0) (12.9.79)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->cad-mllm==0.1.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.9.1.4 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->cad-mllm==0.1.0) (12.9.1.4)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.4.1.4 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->cad-mllm==0.1.0) (11.4.1.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.10.19 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->cad-mllm==0.1.0) (10.3.10.19)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.5.82 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->cad-mllm==0.1.0) (11.7.5.82)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.10.65 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->cad-mllm==0.1.0) (12.5.10.65)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->cad-mllm==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->cad-mllm==0.1.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.9.79 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->cad-mllm==0.1.0) (12.9.79)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.9.86 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->cad-mllm==0.1.0) (12.9.86)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.14.1.1 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->cad-mllm==0.1.0) (1.14.1.1)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->cad-mllm==0.1.0) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->cad-mllm==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/site-packages (from transformers>=4.36.0->cad-mllm==0.1.0) (2025.9.1)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/site-packages (from transformers>=4.36.0->cad-mllm==0.1.0) (0.22.0)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/site-packages (from wandb>=0.16.0->cad-mllm==0.1.0) (8.2.1)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb>=0.16.0->cad-mllm==0.1.0)\n",
            "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/site-packages (from wandb>=0.16.0->cad-mllm==0.1.0) (4.4.0)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/site-packages (from wandb>=0.16.0->cad-mllm==0.1.0) (2.11.7)\n",
            "Collecting sentry-sdk>=2.0.0 (from wandb>=0.16.0->cad-mllm==0.1.0)\n",
            "  Downloading sentry_sdk-2.46.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/site-packages (from pydantic<3->wandb>=0.16.0->cad-mllm==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/site-packages (from pydantic<3->wandb>=0.16.0->cad-mllm==0.1.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/site-packages (from pydantic<3->wandb>=0.16.0->cad-mllm==0.1.0) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate>=0.25.0->cad-mllm==0.1.0) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate>=0.25.0->cad-mllm==0.1.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate>=0.25.0->cad-mllm==0.1.0) (2024.8.30)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb>=0.16.0->cad-mllm==0.1.0)\n",
            "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.16.0->cad-mllm==0.1.0)\n",
            "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard>=2.15.0->cad-mllm==0.1.0) (2.1.5)\n",
            "Downloading editables-0.5-py3-none-any.whl (5.1 kB)\n",
            "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
            "Downloading hatchling-1.27.0-py3-none-any.whl (75 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading pluggy-1.6.0-py3-none-any.whl (20 kB)\n",
            "Downloading pytorch_lightning-2.5.6-py3-none-any.whl (831 kB)\n",
            "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/831.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m831.6/831.6 kB\u001b[0m \u001b[31m171.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/983.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m201.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wandb-0.23.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.2 MB)\n",
            "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/20.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m164.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
            "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
            "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
            "Downloading sentry_sdk-2.46.0-py2.py3-none-any.whl (406 kB)\n",
            "Downloading cython-3.2.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/3.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m147.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trove_classifiers-2025.11.14.15-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: cad-mllm, antlr4-python3-runtime\n",
            "  Building editable for cad-mllm (pyproject.toml): started\n",
            "  Building editable for cad-mllm (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for cad-mllm: filename=cad_mllm-0.1.0-py3-none-any.whl size=1256 sha256=083dc9a5ea2f1fd829e6238c82d39af1544f6829622f11335390d772958f96aa\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6vgqk0hb/wheels/5f/54/49/1e870133dd62c0fc0cab01a9ee61731daca5d1cc7f5d580873\n",
            "  Building wheel for antlr4-python3-runtime (pyproject.toml): started\n",
            "  Building wheel for antlr4-python3-runtime (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144591 sha256=8243fe2de0d3c1e4d20ea4e8e687ff531478a36ef3758ab175263fa1e973b9e2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6vgqk0hb/wheels/1f/be/48/13754633f1d08d1fbfc60d5e80ae1e5d7329500477685286cd\n",
            "Successfully built cad-mllm antlr4-python3-runtime\n",
            "Installing collected packages: trove-classifiers, antlr4-python3-runtime, smmap, sentry-sdk, pluggy, pathspec, omegaconf, lightning-utilities, einops, editables, cython, hatchling, gitdb, gitpython, wandb, torchmetrics, pytorch-lightning, cad-mllm\n",
            "\u001b[?25l\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m 3/18\u001b[0m [sentry-sdk]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m 3/18\u001b[0m [sentry-sdk]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m 4/18\u001b[0m [pluggy]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m 8/18\u001b[0m [einops]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m10/18\u001b[0m [cython]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m10/18\u001b[0m [cython]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m10/18\u001b[0m [cython]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m10/18\u001b[0m [cython]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m10/18\u001b[0m [cython]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m12/18\u001b[0m [gitdb]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m14/18\u001b[0m [wandb]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m14/18\u001b[0m [wandb]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m14/18\u001b[0m [wandb]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m14/18\u001b[0m [wandb]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m14/18\u001b[0m [wandb]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m14/18\u001b[0m [wandb]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m14/18\u001b[0m [wandb]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m14/18\u001b[0m [wandb]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m14/18\u001b[0m [wandb]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m14/18\u001b[0m [wandb]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m14/18\u001b[0m [wandb]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m14/18\u001b[0m [wandb]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m14/18\u001b[0m [wandb]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m15/18\u001b[0m [torchmetrics]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m15/18\u001b[0m [torchmetrics]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m15/18\u001b[0m [torchmetrics]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m15/18\u001b[0m [torchmetrics]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m16/18\u001b[0m [pytorch-lightning]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m16/18\u001b[0m [pytorch-lightning]\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m16/18\u001b[0m [pytorch-lightning]\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m18/18\u001b[0m [cad-mllm]\n",
            "\u001b[?25h\r\u001b[1A\u001b[2KSuccessfully installed antlr4-python3-runtime-4.9.3 cad-mllm-0.1.0 cython-3.2.1 editables-0.5 einops-0.8.1 gitdb-4.0.12 gitpython-3.1.45 hatchling-1.27.0 lightning-utilities-0.15.2 omegaconf-2.3.0 pathspec-0.12.1 pluggy-1.6.0 pytorch-lightning-2.5.6 sentry-sdk-2.46.0 smmap-5.0.2 torchmetrics-1.8.2 trove-classifiers-2025.11.14.15 wandb-0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "scrolled": true
      },
      "source": [
        "# # Generate\n",
        "# print(\"Generating...\")\n",
        "# prompt = \"Generate a simple cylinder\"\n",
        "# inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
        "\n",
        "# with torch.no_grad():\n",
        "#   output_ids = model.generate(\n",
        "#       **inputs,\n",
        "#       max_length=4096,\n",
        "#       temperature=0.7,\n",
        "#       top_p=0.9,\n",
        "#       do_sample=True,\n",
        "#       pad_token_id=tokenizer.pad_token_id,\n",
        "#       eos_token_id=tokenizer.eos_token_id,\n",
        "#   )\n",
        "\n",
        "# output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "# print(\"\\nGenerated CAD:\")\n",
        "# print(output_text)\n",
        "# print(\"done\")\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "import json\n",
        "with open(\"/mnt/l43d/adapter_config.json\") as f:\n",
        "  config = json.load(f)\n",
        "  print(\"LoRA Config:\")\n",
        "  print(json.dumps(config, indent=2))\n",
        "\n",
        "# 2. Check training state\n",
        "import torch\n",
        "trainer_state = torch.load(\"/mnt/l43d/trainer_state.pt\", weights_only=False)\n",
        "print(\"\\nTraining Info:\")\n",
        "print(f\"Best metric: {trainer_state.get('best_metric', 'N/A')}\")\n",
        "print(f\"Best model checkpoint: {trainer_state.get('best_model_checkpoint', 'N/A')}\")\n",
        "print(f\"Total steps: {trainer_state.get('global_step', 'N/A')}\")\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LoRA Config:\n",
            "{\n",
            "  \"alpha_pattern\": {},\n",
            "  \"auto_mapping\": null,\n",
            "  \"base_model_name_or_path\": \"Qwen/Qwen3-8B\",\n",
            "  \"bias\": \"none\",\n",
            "  \"corda_config\": null,\n",
            "  \"eva_config\": null,\n",
            "  \"exclude_modules\": null,\n",
            "  \"fan_in_fan_out\": false,\n",
            "  \"inference_mode\": true,\n",
            "  \"init_lora_weights\": true,\n",
            "  \"layer_replication\": null,\n",
            "  \"layers_pattern\": null,\n",
            "  \"layers_to_transform\": null,\n",
            "  \"loftq_config\": {},\n",
            "  \"lora_alpha\": 128,\n",
            "  \"lora_bias\": false,\n",
            "  \"lora_dropout\": 0.1,\n",
            "  \"megatron_config\": null,\n",
            "  \"megatron_core\": \"megatron.core\",\n",
            "  \"modules_to_save\": null,\n",
            "  \"peft_type\": \"LORA\",\n",
            "  \"qalora_group_size\": 16,\n",
            "  \"r\": 64,\n",
            "  \"rank_pattern\": {},\n",
            "  \"revision\": null,\n",
            "  \"target_modules\": [\n",
            "    \"q_proj\",\n",
            "    \"o_proj\",\n",
            "    \"gate_proj\",\n",
            "    \"down_proj\",\n",
            "    \"v_proj\",\n",
            "    \"k_proj\",\n",
            "    \"up_proj\"\n",
            "  ],\n",
            "  \"target_parameters\": null,\n",
            "  \"task_type\": \"CAUSAL_LM\",\n",
            "  \"trainable_token_indices\": null,\n",
            "  \"use_dora\": false,\n",
            "  \"use_qalora\": false,\n",
            "  \"use_rslora\": false\n",
            "}\n",
            "\n",
            "Training Info:\n",
            "Best metric: N/A\n",
            "Best model checkpoint: N/A\n",
            "Total steps: N/A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1: Generate Raw Output\n",
        "### 2. Extract, Repair, and Save JSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "from transformers import StoppingCriteria, StoppingCriteriaList\n",
        "\n",
        "class BraceBalancingStoppingCriteria(StoppingCriteria):\n",
        "    def __init__(self, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.brace_depth = 0\n",
        "        self.has_started = False\n",
        "        \n",
        "    def __call__(self, input_ids, scores, **kwargs):\n",
        "        # Get the last generated token\n",
        "        last_token_id = input_ids[0, -1]\n",
        "        last_token = self.tokenizer.decode(last_token_id)\n",
        "        \n",
        "        # Count braces in this token\n",
        "        if '{' in last_token:\n",
        "            self.brace_depth += last_token.count('{')\n",
        "            self.has_started = True\n",
        "        \n",
        "        if '}' in last_token:\n",
        "            self.brace_depth -= last_token.count('}')\n",
        "            \n",
        "        # STOP CONDITION:\n",
        "        # We have started (depth went up) AND we are back to zero (depth came down)\n",
        "        if self.has_started and self.brace_depth <= 0:\n",
        "            return True # Stop generating!\n",
        "            \n",
        "        return False\n",
        "\n",
        "stopping_criteria = StoppingCriteriaList([BraceBalancingStoppingCriteria(tokenizer)])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "import torch\n",
        "import os  \n",
        "\n",
        "# 1. Define your prompt\n",
        "prompt_list = [\n",
        "    # \"Generate a CAD model with a cylindrical component featuring two large circular ends connected by a rectangular section. The cylindrical ends have hollow centers, and the rectangular section has a smaller circular hole near one end.\",\n",
        "    # \"Generate a CAD model with a cylinder\",\n",
        "    \"Generate a CAD model with a cube\"\n",
        "]\n",
        "\n",
        "# 2. Prepare Input\n",
        "for idx in range(len(prompt_list)):\n",
        "    # 3. Generate with Anti-Repetition Settings\n",
        "    prompt = prompt_list[idx]\n",
        "    name = prompt[28:32] + \"higher_temp\" # Exclude \"Generate a CAD model with \"\n",
        "    print(f\"Generating for prompt {idx+1}: '{prompt}'...\")\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
        "\n",
        "    # generated_cad_0_10k.txt:\n",
        "    # with torch.no_grad():\n",
        "    #     output_ids = model.generate(\n",
        "    #         **inputs,\n",
        "    #         max_new_tokens=10240,    \n",
        "    #         repetition_penalty=1.2,  # <--- KEY FIX: Prevents infinite loops\n",
        "    #         temperature=0.2,         # Low temp = more logical/structured output\n",
        "    #         top_p=0.95,\n",
        "    #         do_sample=True,\n",
        "    #         pad_token_id=tokenizer.pad_token_id,\n",
        "    #         eos_token_id=tokenizer.eos_token_id,\n",
        "    #     )\n",
        "\n",
        "    # generated_cad_0_4096.txt:\n",
        "    # with torch.no_grad():\n",
        "    #   output_ids = model.generate(\n",
        "    #       **inputs,\n",
        "    #       max_length=4096,\n",
        "    #       repetition_penalty=1.2,\n",
        "    #       temperature=0.2,\n",
        "    #       top_p=0.9,\n",
        "    #       do_sample=True,\n",
        "    #       pad_token_id=tokenizer.pad_token_id,\n",
        "    #       eos_token_id=tokenizer.eos_token_id,\n",
        "    #   )\n",
        "\n",
        "    # generated_cad_0_stopping_criteria.txt:\n",
        "    # with torch.no_grad():\n",
        "    #     output_ids = model.generate(\n",
        "    #         **inputs,\n",
        "    #         max_new_tokens=10240,     \n",
        "    #         repetition_penalty=1.2,\n",
        "    #         temperature=0.2,\n",
        "    #         top_p=0.95,\n",
        "    #         do_sample=True,\n",
        "    #         pad_token_id=tokenizer.pad_token_id,\n",
        "    #         eos_token_id=tokenizer.eos_token_id,\n",
        "    #         stopping_criteria=stopping_criteria \n",
        "    # )\n",
        "\n",
        "    # with torch.no_grad():\n",
        "    #     output_ids = model.generate(\n",
        "    #         **inputs,\n",
        "    #         max_new_tokens=10240,\n",
        "    #         repetition_penalty=1.2,\n",
        "    #         temperature=0.2,\n",
        "    #         top_p=0.95,\n",
        "    #         do_sample=True,\n",
        "    #         pad_token_id=tokenizer.pad_token_id,\n",
        "    #         eos_token_id=tokenizer.eos_token_id,\n",
        "    #         # \u2717 REMOVE THIS: stopping_criteria=stopping_criteria\n",
        "    #     )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_length=4096,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "      )\n",
        "    \n",
        "    # 4. Decode to variable (used in next cell)\n",
        "    raw_output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "    \n",
        "    # 5. Preview\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"RAW OUTPUT PREVIEW (First 500 chars)\")\n",
        "    print(\"=\"*40)\n",
        "    print(raw_output_text[:500] + \"...\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # Step 2: save raw_ouput_text to debug:\n",
        "    output_dir = \"./generated_cad\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    raw_txt_path = os.path.join(output_dir, f\"generated_cad_{idx}_{name}.txt\")\n",
        "    \n",
        "    with open(raw_txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(raw_output_text)\n",
        "\n",
        "    print(f\"\u2713 Saved raw output text to: {raw_txt_path}\")\n",
        "\n",
        "    # Step 3: output json\n",
        "    import sys\n",
        "    import subprocess\n",
        "    try:\n",
        "        import json_repair\n",
        "    except ImportError:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"json_repair\"])\n",
        "        import json_repair\n",
        "    \n",
        "    import json\n",
        "    import os\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"FINAL MERGE & SAVE STRATEGY\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # 1. Repair the JSON\n",
        "    decoded_object = json_repair.repair_json(raw_output_text, return_objects=True)\n",
        "    \n",
        "    # 2. Smart Merge Logic\n",
        "    final_cad_model = {}\n",
        "    \n",
        "    if isinstance(decoded_object, list):\n",
        "        print(f\"\u26a0 Found a LIST of {len(decoded_object)} objects. Merging them...\")\n",
        "        # Iterate through every fragment and merge them into one master dictionary\n",
        "        for item in decoded_object:\n",
        "            if isinstance(item, dict):\n",
        "                # .update() adds new keys and overwrites existing ones\n",
        "                # This combines the \"entities\" block with the \"bounding_box\" block\n",
        "                final_cad_model.update(item)\n",
        "    elif isinstance(decoded_object, dict):\n",
        "        print(\"\u2713 Found a single valid dictionary.\")\n",
        "        final_cad_model = decoded_object\n",
        "    else:\n",
        "        print(f\"\u2717 Unexpected type: {type(decoded_object)}\")\n",
        "    \n",
        "    # 3. Validation and Save\n",
        "    if final_cad_model and \"entities\" in final_cad_model:\n",
        "        entity_count = len(final_cad_model['entities'])\n",
        "        print(f\"\u2713 Valid CAD Model Constructed!\")\n",
        "        print(f\"\u2713 Found {entity_count} entities.\")\n",
        "    \n",
        "        # Save\n",
        "        output_dir = \"./generated_cad\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        save_path = os.path.join(output_dir, f\"generated_cad_{idx}_{name}.json\")\n",
        "    \n",
        "        with open(save_path, 'w') as f:\n",
        "            json.dump(final_cad_model, f, indent=2)\n",
        "        \n",
        "        print(f\"\u2713 Saved to: {save_path}\")\n",
        "    \n",
        "    elif final_cad_model:\n",
        "        print(\"\u26a0 Saved, but 'entities' key is missing. Check output manually.\")\n",
        "        # Save anyway to inspect\n",
        "        with open(\"./generated_cad/debug_fragment.json\", 'w') as f:\n",
        "            json.dump(final_cad_model, f, indent=2)\n",
        "    else:\n",
        "        print(\"\u2717 Failed to construct any valid object.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating for prompt 1: 'Generate a CAD model with a cube'...\n",
            "\n",
            "========================================\n",
            "RAW OUTPUT PREVIEW (First 500 chars)\n",
            "========================================\n",
            "Generate a CAD model with a cube featuring a hollow center.\n",
            "{\"entities\":{\"F68b8u7Xk8z5bqY_0\":{\"transform\":{\"origin\":{\"y\":0.0,\"x\":0.0,\"z\":0.0},\"y_axis\":{\"y\":0.0,\"x\":-0.0,\"z\":1.0},\"x_axis\":{\"y\":0.0,\"x\":1.0,\"z\":0.0},\"z_axis\":{\"y\":-1.0,\"x\":0.0,\"z\":0.0}},\"type\":\"Sketch\",\"name\":\"Sketch 1\",\"profiles\":{\"JGC\":{\"loops\":[{\"is_outer\":true,\"profile_curves\":[{\"type\":\"Line3D\",\"start_point\":{\"y\":0.025,\"x\":0.025,\"z\":0.0},\"curve\":\"JGB\",\"end_point\":{\"y\":0.025,\"x\":-0.025,\"z\":0.0}},{\"type\":\"Line3D\",\"start_point\":{\"y...\n",
            "========================================\n",
            "\u2713 Saved raw output text to: ./generated_cad/generated_cad_0_cubehigher_temp.txt\n",
            "Collecting json_repair\n",
            "  Downloading json_repair-0.54.2-py3-none-any.whl.metadata (12 kB)\n",
            "Downloading json_repair-0.54.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: json_repair\n",
            "Successfully installed json_repair-0.54.2\n",
            "\n",
            "============================================================\n",
            "FINAL MERGE & SAVE STRATEGY\n",
            "============================================================\n",
            "\u26a0 Found a LIST of 3 objects. Merging them...\n",
            "\u2713 Valid CAD Model Constructed!\n",
            "\u2713 Found 1 entities.\n",
            "\u2713 Saved to: ./generated_cad/generated_cad_0_cubehigher_temp.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}