# -*- coding: utf-8 -*-
"""Pointcloud_preprocess

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jMoXoxPHwPSyqngR8HXNxEhD1_-SjmyM
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install "pip<24.1"
!pip install -q cadquery-ocp trimesh tqdm networkx

import os, glob, json
from pathlib import Path

datapath = "/content/drive/MyDrive/MSCD_24_25/course_lectures/25Fall/Omni-CAD-subset"

txt_dir = os.path.join(datapath, "txt")
pc_dir  = os.path.join(datapath, "point_cloud")
step_dir = os.path.join(datapath, "step")

print("txt_dir:", txt_dir)
print("point_cloud_dir:", pc_dir)
print("step_dir:", step_dir)

print("\nFiles in txt:")
print(os.listdir(txt_dir))

print("\nSample files in point_cloud:")
pc_files = os.listdir(pc_dir)
print(pc_files[:10])

print("\nSample files in step:")
step_files = os.listdir(step_dir)
print(step_files[:10])

import json
import numpy as np
from pathlib import Path
from tqdm import tqdm

# ---- å¿…è¦çš„ OpenCascade importsï¼ˆè¿™å‡ ä¸ªå¿…é¡»æœ‰ï¼‰----
from OCP.STEPControl import STEPControl_Reader
from OCP.BRepMesh import BRepMesh_IncrementalMesh
from OCP.TopExp import TopExp_Explorer
from OCP.TopAbs import TopAbs_FACE
from OCP.BRep import BRep_Tool
from OCP.TopLoc import TopLoc_Location


def step_to_dense_points_in_memory(step_path: Path, deflection: float = 0.5) -> np.ndarray:
    """
    ç”¨ OpenCascade ç›´æ¥åœ¨å†…å­˜é‡ŒæŠŠ STEP ä¸‰è§’åŒ–ï¼Œ
    æŠŠæ‰€æœ‰ä¸‰è§’ç½‘æ ¼çš„é¡¶ç‚¹æ”¶é›†æˆä¸€ä¸ª dense point cloud.
    è¿”å›: (N, 3) çš„ numpy æ•°ç»„
    """
    step_reader = STEPControl_Reader()
    status = step_reader.ReadFile(str(step_path))
    if status != 1:
        raise RuntimeError(f"Failed to read STEP: {step_path}")

    # æŠŠ STEP è½¬æˆ shape
    step_reader.TransferRoot()
    shape = step_reader.Shape()

    # å¯¹ shape åšä¸‰è§’åŒ–ï¼ˆdeflection è¶Šå°ç½‘æ ¼è¶Šå¯†ï¼Œä½†è¶Šæ…¢ï¼‰
    BRepMesh_IncrementalMesh(shape, deflection)

    # éå†æ‰€æœ‰ FACEï¼Œå–æ¯ä¸ªé¢çš„ä¸‰è§’åŒ–èŠ‚ç‚¹
    exp = TopExp_Explorer(shape, TopAbs_FACE)
    all_pts = []

    while exp.More():
        face = exp.Current()          # âœ… è¿™é‡Œç›´æ¥æ‹¿å½“å‰é¢ï¼Œä¸ç”¨ topods_Face
        loc = TopLoc_Location()
        triangulation = BRep_Tool.Triangulation(face, loc)

        if triangulation is None:
            exp.Next()
            continue

        nodes = triangulation.Nodes()
        nb_nodes = triangulation.NbNodes()

        # OCCT çš„ array æ˜¯ 1-based index
        for i in range(1, nb_nodes + 1):
            pnt = nodes.Value(i)
            x, y, z = pnt.X(), pnt.Y(), pnt.Z()
            all_pts.append((x, y, z))

        exp.Next()

    if not all_pts:
        raise RuntimeError(f"No triangulation result for STEP: {step_path}")

    pts = np.array(all_pts, dtype=np.float64)
    return pts  # (N, 3)


def fps_downsample(points: np.ndarray, n_samples: int = 4096) -> np.ndarray:
    """
    ç®€å•çš„ Farthest Point Sampling (FPS)
    points: (N, 3)
    è¿”å›: (n_samples, 3)
    """
    N = points.shape[0]
    if N <= n_samples:
        return points

    selected = np.zeros(n_samples, dtype=int)
    # éšæœºèµ·ç‚¹
    selected[0] = np.random.randint(0, N)
    distances = np.full(N, np.inf)

    for i in range(1, n_samples):
        last = points[selected[i - 1]]
        dist = np.linalg.norm(points - last, axis=1)
        distances = np.minimum(distances, dist)
        selected[i] = np.argmax(distances)

    return points[selected]


def normalize_pc(pc: np.ndarray) -> np.ndarray:
    """
    å¹³ç§»åˆ°è´¨å¿ƒä¸º 0ï¼Œç¼©æ”¾åˆ°å•ä½çƒ
    """
    pc = pc - pc.mean(axis=0, keepdims=True)
    scale = np.max(np.linalg.norm(pc, axis=1))
    pc = pc / (scale + 1e-8)
    return pc.astype(np.float32)


def preprocess_pc_from_step_dir(
    step_root: str,
    out_root: str,
    n_samples: int = 4096,
    deflection: float = 0.5,
    limit_n: int | None = None,
):
    """
    ç›´æ¥ä» step_root ä¸‹æ‰€æœ‰ .step / .stp ç”Ÿæˆ point_cloud_small:

      STEP -> (in-memory triangulation) -> dense points -> FPS -> normalize -> .npz

    ä¸å†å†™ STL æ–‡ä»¶ï¼Œä¹Ÿä¸éœ€è¦ trimesh.
    """
    step_root = Path(step_root)
    out_root = Path(out_root)
    out_root.mkdir(parents=True, exist_ok=True)

    step_files = list(step_root.rglob("*.step")) + list(step_root.rglob("*.stp"))
    print("found STEP files:", len(step_files))

    if limit_n is not None:
        step_files = step_files[:limit_n]
        print(f"âš ï¸ Only processing first {limit_n} files for testing")

    for step_path in tqdm(step_files):
        rel = step_path.relative_to(step_root).with_suffix("")  # e.g. 0002/00020000_00001
        out_path = out_root / rel.with_suffix(".npz")
        out_path.parent.mkdir(parents=True, exist_ok=True)

        if out_path.exists():
            continue

        try:
            dense_pts = step_to_dense_points_in_memory(step_path, deflection=deflection)
            pc = fps_downsample(dense_pts, n_samples=n_samples)
            pc = normalize_pc(pc)
            np.savez_compressed(out_path, points=pc)
        except Exception as e:
            print(f"[error] {step_path}: {e}")
            continue

    print("Done preprocessing from step_root only (in-memory triangulation)!")

import os
import numpy as np
from pathlib import Path
from tqdm import tqdm

# OpenCascade
from OCP.STEPControl import STEPControl_Reader
from OCP.BRepMesh import BRepMesh_IncrementalMesh
from OCP.StlAPI import StlAPI_Writer

import trimesh


def step_to_stl(step_path: Path,
                stl_path: Path,
                linear_deflection: float = 0.5,
                angular_deflection: float = 0.5,
                parallel: bool = True) -> None:
    """
    ç”¨ OpenCascade æŠŠ STEP è½¬æˆ STL ç½‘æ ¼æ–‡ä»¶ï¼ˆå‚è€ƒ CadQuery çš„å†™æ³•ï¼‰
    """
    step_reader = STEPControl_Reader()
    status = step_reader.ReadFile(str(step_path))
    if status != 1:
        raise RuntimeError(f"Failed to read STEP: {step_path}")

    # è½¬æˆ shape
    step_reader.TransferRoot()
    shape = step_reader.Shape()

    # å…ˆåšä¸‰è§’åŒ–
    BRepMesh_IncrementalMesh(shape,
                             linear_deflection,
                             True,   # relative
                             angular_deflection,
                             parallel)

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    stl_path.parent.mkdir(parents=True, exist_ok=True)

    # å†™ STLï¼ˆæ³¨æ„ï¼šè¿™é‡Œç”¨ ASCIIMode å±æ€§ï¼Œä¸ç”¨ SetASCIIModeï¼‰
    writer = StlAPI_Writer()
    writer.ASCIIMode = False   # binary STLï¼Œæ–‡ä»¶å°ä¸€ç‚¹
    ok = writer.Write(shape, str(stl_path))

    if (not ok) or (not stl_path.exists()):
        raise RuntimeError(f"Failed to write STL: {stl_path}")

def stl_to_dense_points(stl_path: Path, n_dense: int = 50000) -> np.ndarray:
    """
    ç”¨ trimesh ä» STL è¡¨é¢å‡åŒ€é‡‡æ ·ç‚¹
    """
    mesh = trimesh.load_mesh(str(stl_path), process=False)
    if mesh.is_empty:
        raise RuntimeError(f"Empty mesh for STL: {stl_path}")
    pts, _ = trimesh.sample.sample_surface(mesh, n_dense)
    return pts.astype(np.float64)


def fps_downsample(points: np.ndarray, n_samples: int = 4096) -> np.ndarray:
    """
    ç®€å• Farthest Point Sampling (FPS)
    """
    N = points.shape[0]
    if N <= n_samples:
        return points

    selected = np.zeros(n_samples, dtype=int)
    selected[0] = np.random.randint(0, N)
    distances = np.full(N, np.inf)

    for i in range(1, n_samples):
        last = points[selected[i - 1]]
        dist = np.linalg.norm(points - last, axis=1)
        distances = np.minimum(distances, dist)
        selected[i] = np.argmax(distances)

    return points[selected]


def normalize_pc(pc: np.ndarray) -> np.ndarray:
    """
    å¹³ç§»åˆ°è´¨å¿ƒä¸º 0ï¼Œç¼©æ”¾åˆ°å•ä½çƒ
    """
    pc = pc - pc.mean(axis=0, keepdims=True)
    scale = np.max(np.linalg.norm(pc, axis=1))
    pc = pc / (scale + 1e-8)
    return pc.astype(np.float32)

def preprocess_pc_from_step_dir(
    step_root: str,
    out_root: str,
    n_dense: int = 50000,
    n_samples: int = 4096,
    tmp_stl_root: str | None = None,
    limit_n: int | None = None,
):
    """
    STEP ç›®å½• â†’ point_cloud_small ç›®å½•ï¼š

    STEP -> STL (ä¸´æ—¶) -> trimesh é‡‡æ ·è¡¨é¢ç‚¹ -> FPS -> normalize -> .npz
    """
    step_root = Path(step_root)
    out_root = Path(out_root)
    out_root.mkdir(parents=True, exist_ok=True)

    tmp_stl_root_path = None
    if tmp_stl_root is not None:
        tmp_stl_root_path = Path(tmp_stl_root)
        tmp_stl_root_path.mkdir(parents=True, exist_ok=True)

    # æ‰¾æ‰€æœ‰ STEP
    step_files = list(step_root.rglob("*.step")) + list(step_root.rglob("*.stp"))
    print("found STEP files:", len(step_files))

    if limit_n is not None:
        step_files = step_files[:limit_n]
        print(f"âš ï¸ Only processing first {limit_n} files for testing")

    for step_path in tqdm(step_files):
        rel = step_path.relative_to(step_root).with_suffix("")  # 0002/00020000_00001
        out_path = out_root / rel.with_suffix(".npz")
        out_path.parent.mkdir(parents=True, exist_ok=True)

        if out_path.exists():
            continue

        # å†³å®š STL å­˜å“ª
        if tmp_stl_root_path is not None:
            stl_path = tmp_stl_root_path / rel.with_suffix(".stl")
            stl_path.parent.mkdir(parents=True, exist_ok=True)
        else:
            stl_path = step_path.with_suffix(".stl")

        try:
            # STEP â†’ STL
            step_to_stl(step_path, stl_path)

            # STL â†’ dense pc
            dense_pts = stl_to_dense_points(stl_path, n_dense=n_dense)

            # FPS + normalize
            pc = fps_downsample(dense_pts, n_samples=n_samples)
            pc = normalize_pc(pc)

            # ä¿å­˜
            out_path.parent.mkdir(parents=True, exist_ok=True)
            np.savez_compressed(out_path, points=pc)

        except Exception as e:
            print(f"[error] {step_path}: {e}")
            continue
        finally:
            # å¦‚æœæ˜¯ä¸´æ—¶ STLï¼Œå¯ä»¥åˆ æ‰èŠ‚çœç©ºé—´
            if tmp_stl_root_path is not None and stl_path.exists():
                os.remove(stl_path)

    print("Done preprocessing from step_root (STEP â†’ STL â†’ point cloud)!")

from pathlib import Path

datapath = "/content/drive/MyDrive/MSCD_24_25/course_lectures/25Fall/Omni-CAD-subset"
step_root = f"{datapath}/step"
out_root  = f"{datapath}/point_cloud_small"
tmp_stl_root = "/content/tmp_stl"   # ä¸´æ—¶æ–‡ä»¶æ”¾æœ¬åœ°ï¼Œé¿å… GDrive æ…¢ + è·¯å¾„å¥‡æ€ª

print("step_root exists?", Path(step_root).exists())
print("out_root:", out_root)

# preprocess_pc_from_step_dir(
#     step_root=step_root,
#     out_root=out_root,
#     n_dense=20000,    # æµ‹è¯•ç”¨ï¼Œå…ˆå°ä¸€ç‚¹
#     n_samples=2048,   # ç‚¹äº‘å¤§å°
#     tmp_stl_root=tmp_stl_root,
#     limit_n=1,        # ğŸ‘ˆ å…ˆå¤„ç† 3 ä¸ª STEP
# )

import numpy as np
from pathlib import Path

out_root_path = Path(out_root)
small_files = list(out_root_path.rglob("*.npz"))
print("num small pcs:", len(small_files))
print("examples:", small_files[:3])

if small_files:
    data = np.load(small_files[0])
    print("keys:", data.files)
    pts = data["points"]
    print("points shape:", pts.shape)
    print("min:", pts.min(), "max:", pts.max())

import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 (Colab éœ€è¦è¿™ä¸ª import)

# é€‰ä¸€ä¸ªç‚¹äº‘æ–‡ä»¶
pc_path = small_files[0]   # æˆ–è€…æ‰‹åŠ¨é€‰æŸä¸ªè·¯å¾„
data = np.load(pc_path)
pts = data["points"]       # (N, 3)

print("points shape:", pts.shape)

# å¦‚æœç‚¹å¤ªå¤šï¼Œå¯ä»¥å†éšæœºé‡‡æ ·ä¸€ä¸‹
N = pts.shape[0]
max_show = 2000
if N > max_show:
    idx = np.random.choice(N, max_show, replace=False)
    pts_vis = pts[idx]
else:
    pts_vis = pts

fig = plt.figure(figsize=(6, 6))
ax = fig.add_subplot(111, projection="3d")

x, y, z = pts_vis[:, 0], pts_vis[:, 1], pts_vis[:, 2]

# ç”¨ z ä½œä¸ºé¢œè‰²ï¼Œçœ‹ä¸€ä¸‹é«˜åº¦å˜åŒ–
sc = ax.scatter(x, y, z, s=3, alpha=0.8, c=z)

ax.set_xlabel("X")
ax.set_ylabel("Y")
ax.set_zlabel("Z")
ax.set_title(f"Point Cloud: {pc_path.name}")

plt.show()

!du -sh "/content/drive/MyDrive/MSCD_24_25/course_lectures/25Fall/Omni-CAD-subset/point_cloud_small"

N = 2048
bytes_per_pc = N * 3 * 4
print("bytes:", bytes_per_pc, "â‰ˆ", bytes_per_pc / 1024, "KB")

from pathlib import Path

datapath = "/content/drive/MyDrive/MSCD_24_25/course_lectures/25Fall/Omni-CAD-subset"

# æŠŠ step_root / out_root / tmp_stl_root ç»Ÿä¸€æˆ Path å¯¹è±¡
step_root = Path(datapath) / "step"
out_root  = Path(datapath) / "point_cloud_small"
tmp_stl_root = Path("/content/tmp_stl")

start_from = "0020"

subdirs = sorted([p for p in step_root.iterdir() if p.is_dir()])
print("subdirs:", [d.name for d in subdirs])

# æ‰¾åˆ°èµ·å§‹ indexï¼ˆä¾‹å¦‚ä» 0011 å¼€å§‹ï¼‰
start_idx = 0
for i, d in enumerate(subdirs):
    if d.name >= start_from:
        start_idx = i
        break

for sub in subdirs[start_idx:]:
    print(f"\n=== Processing folder {sub.name} ===")
    sub_step_root = sub
    sub_out_root  = out_root / sub.name
    sub_tmp_stl   = tmp_stl_root / sub.name

    preprocess_pc_from_step_dir(
        step_root=str(sub_step_root),
        out_root=str(sub_out_root),
        n_dense=50000,
        n_samples=2048,
        tmp_stl_root=str(sub_tmp_stl),
        limit_n=None,
    )

import os
import datetime
import numpy as np
from pathlib import Path
from tqdm import tqdm

# å‡è®¾ä½ å·²ç»å®šä¹‰äº†ï¼š
# step_to_stl(step_path, stl_path)
# stl_to_dense_points(stl_path, n_dense)
# fps_downsample(points, n_samples)
# normalize_pc(pc)


def preprocess_pc_from_step_dir(
    step_root: str,
    out_root: str,
    n_dense: int = 50000,
    n_samples: int = 4096,
    tmp_stl_root: str | None = None,
    limit_n: int | None = None,
    error_log_path: str | None = None,   # ç°åœ¨æ˜¯ "all logs"
):
    """
    STEP ç›®å½• -> point cloud ç›®å½•ï¼š
    STEP -> STL -> trimesh è¡¨é¢é‡‡æ · -> FPS -> normalize -> .npz

    å¦‚æœ error_log_path ä¸ä¸º Noneï¼Œä¼šæŠŠæ‰€æœ‰æ–‡ä»¶ï¼ˆæˆåŠŸ / å¤±è´¥ï¼‰çš„å¤„ç†ç»“æœå†™åˆ° logã€‚
    """
    step_root = Path(step_root)
    out_root = Path(out_root)
    out_root.mkdir(parents=True, exist_ok=True)

    # å‡†å¤‡æ—¥å¿—æ–‡ä»¶ï¼ˆè®°å½•æ‰€æœ‰ç»“æœï¼‰
    log_file = None
    if error_log_path is not None:
        log_file = Path(error_log_path)
        log_file.parent.mkdir(parents=True, exist_ok=True)
        if not log_file.exists():
            with log_file.open("w") as f:
                f.write("# timestamp | status | step_path | detail\n")

    # ä¸´æ—¶ STL ç›®å½•
    tmp_stl_root_path = None
    if tmp_stl_root is not None:
        tmp_stl_root_path = Path(tmp_stl_root)
        tmp_stl_root_path.mkdir(parents=True, exist_ok=True)

    # æ”¶é›†æ‰€æœ‰ STEP
    step_files = list(step_root.rglob("*.step")) + list(step_root.rglob("*.stp"))
    print("found STEP files:", len(step_files))

    if limit_n is not None:
        step_files = step_files[:limit_n]
        print(f"âš ï¸ Only processing first {limit_n} files for testing")

    for step_path in tqdm(step_files):
        rel = step_path.relative_to(step_root).with_suffix("")  # 0002/00020000_00001
        out_path = out_root / rel.with_suffix(".npz")
        out_path.parent.mkdir(parents=True, exist_ok=True)

        # å†³å®š STL è·¯å¾„
        if tmp_stl_root_path is not None:
            stl_path = tmp_stl_root_path / rel.with_suffix(".stl")
            stl_path.parent.mkdir(parents=True, exist_ok=True)
        else:
            stl_path = step_path.with_suffix(".stl")

        ts = datetime.datetime.now().isoformat(timespec="seconds")

        # å¦‚æœç‚¹äº‘å·²ç»å­˜åœ¨ï¼Œä¹Ÿè®°å½•åˆ° log é‡Œï¼ˆçŠ¶æ€ï¼šSKIPï¼‰
        if out_path.exists():
            msg = f"[{ts}] SKIP | {step_path} | npz exists: {out_path}"
            print(msg)
            if log_file is not None:
                with log_file.open("a") as f:
                    f.write(msg + "\n")
            continue

        try:
            # STEP -> STL
            step_to_stl(step_path, stl_path)

            # STL -> dense points
            dense_pts = stl_to_dense_points(stl_path, n_dense=n_dense)

            # FPS + normalize
            pc = fps_downsample(dense_pts, n_samples=n_samples)
            pc = normalize_pc(pc)

            # å­˜ .npz
            np.savez_compressed(out_path, points=pc)

            # æˆåŠŸä¹Ÿå†™ logï¼ˆçŠ¶æ€ï¼šOKï¼‰
            msg = f"[{ts}] OK   | {step_path} | saved: {out_path}"
            print(msg)
            if log_file is not None:
                with log_file.open("a") as f:
                    f.write(msg + "\n")

        except Exception as e:
            # å¤±è´¥å†™ logï¼ˆçŠ¶æ€ï¼šERRORï¼‰
            msg = f"[{ts}] ERROR| {step_path} | {repr(e)}"
            print(msg)
            if log_file is not None:
                with log_file.open("a") as f:
                    f.write(msg + "\n")
            continue

        finally:
            # æ¸…ç†ä¸´æ—¶ STL
            if tmp_stl_root_path is not None and stl_path.exists():
                try:
                    os.remove(stl_path)
                except OSError:
                    pass

    print("Done preprocessing from step_root (STEP â†’ STL â†’ point cloud)!")

from pathlib import Path

datapath = "/content/drive/MyDrive/MSCD_24_25/course_lectures/25Fall/Omni-CAD-subset"
log_path = Path(datapath) / "logs" / "step2pc_all.txt"   # ğŸ‘ˆ ç°åœ¨è®°å½•å…¨éƒ¨ç»“æœ

# æŠŠ step_root / out_root / tmp_stl_root ç»Ÿä¸€æˆ Path å¯¹è±¡
step_root = Path(datapath) / "step"
out_root  = Path(datapath) / "point_cloud_small"
tmp_stl_root = Path("/content/tmp_stl")

start_from = "0030"

subdirs = sorted([p for p in step_root.iterdir() if p.is_dir()])
print("subdirs:", [d.name for d in subdirs])

# æ‰¾åˆ°èµ·å§‹ index
start_idx = 0
for i, d in enumerate(subdirs):
    if d.name >= start_from:
        start_idx = i
        break

for sub in subdirs[start_idx:]:
    print(f"\n=== Processing folder {sub.name} ===")
    sub_step_root = sub
    sub_out_root  = out_root / sub.name
    sub_tmp_stl   = tmp_stl_root / sub.name

    preprocess_pc_from_step_dir(
        step_root=str(sub_step_root),
        out_root=str(sub_out_root),
        n_dense=50000,
        n_samples=2048,
        tmp_stl_root=str(sub_tmp_stl),
        limit_n=None,
        error_log_path=str(log_path),   # ğŸ‘ˆ ç°åœ¨æ˜¯â€œå…¨é‡ logâ€
    )